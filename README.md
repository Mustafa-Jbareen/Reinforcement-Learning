# Reinforcement Learning Homework Assignments
This repository contains three assignments completed during a Reinforcement Learning course. Each assignment focuses on key RL techniques, coding tasks, and experimentation.

## Homework 1: Multi-Armed Bandit Problem
This homework involves solving the classic Multi-Armed Bandit problem, where I implemented strategies like Îµ-greedy, Upper Confidence Bound (UCB), and Thompson Sampling to address the exploration-exploitation trade-off. I conducted experiments to compare how these strategies perform in maximizing cumulative rewards.

## Homework 2: Dynamic Programming and Policy Iteration
In this assignment, I implemented Value Iteration and Policy Iteration algorithms to solve a grid-world problem. These dynamic programming techniques were used to calculate optimal policies and value functions. I compared their convergence and efficiency in environments where the model was fully known.

## Homework 3: Q-Learning, SARSA, and Deep Reinforcement Learning
This homework expanded into both traditional and deep reinforcement learning techniques. I implemented Q-Learning and SARSA in classic environments like Frozen Lake to observe the differences between on-policy (SARSA) and off-policy (Q-Learning) algorithms.

For the deep reinforcement learning part, I used a Deep Q-Network (DQN) to solve more complex environments, specifically "CartPole" and "Breakout". In these games, I used neural networks to approximate the Q-values, leveraging techniques like experience replay and target networks to stabilize training and improve performance. The task emphasized the challenges of applying RL to high-dimensional state spaces and learning directly from raw pixel data in the case of Breakout.

